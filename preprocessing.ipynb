{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 16,
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
   "execution_count": 16,
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T18:30:18.018668Z",
     "start_time": "2023-04-07T18:30:17.998803Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.utils import shuffle"
=======
    "import os"
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
    "import os"
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Préparation des données (Preprocessing)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>Lecture des mails depuis des fichiers<h3>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 17,
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
   "execution_count": 17,
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T18:30:18.030176Z",
     "start_time": "2023-04-07T18:30:18.018668Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
<<<<<<< HEAD
      "text/plain": "['easy_ham', 'hard_ham', 'spam']"
     },
     "execution_count": 2,
=======
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
      "text/plain": [
       "['easy_ham', 'hard_ham', 'spam']"
      ]
     },
     "execution_count": 17,
<<<<<<< HEAD
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"./dataset\"\n",
    "directories=os.listdir(path)\n",
    "directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h2></h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Suppresion Des Balises HTML</h2>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": null,
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
   "execution_count": null,
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(email : str)->str:\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    soup = BeautifulSoup(email, 'html.parser')\n",
    "    new_email = soup.get_text()\n",
    "    return new_email"
=======
    "    #insert code"
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
    "    #insert code"
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Normalisation Des URLS</h2>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": null,
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
   "execution_count": null,
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_normalization(email : str)->str:\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    url_regex = r'(http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+)'\n",
    "    new_email = re.sub(url_regex, 'httpaddr', email)\n",
    "    return new_email"
=======
    "    #insert code"
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
    "    #insert code"
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Normalisation Des Adresses Email</h2>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def address_normalization(email, remplacement=\"emailaddr\"):\n",
    "    # Expression régulière pour détecter les adresses email\n",
    "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "\n",
    "    # Remplacement des adresses email par la chaîne de remplacement emailaddr\n",
    "    normalized_email = re.sub(email_pattern, remplacement, email)\n",
    "\n",
    "    return normalized_email"
=======
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def address_normalization(email : str)->str:\n",
    "    #insert code"
<<<<<<< HEAD
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Normalisation Des Nombres</h2>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_normalization(email, Remplacement=\"number\"):\n",
    "    # Expression régulière pour détecter les nombres\n",
    "    number_pattern = r'\\d+'\n",
    "\n",
    "    # Remplacement des nombres par la chaîne de remplacement\n",
    "    normalized_email = re.sub(number_pattern, Remplacement, email)\n",
    "\n",
    "    return normalized_email"
=======
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_normalization(email : str)->str:\n",
    "    #insert code"
<<<<<<< HEAD
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Normalisation Des Dollars</h2>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
=======
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
<<<<<<< HEAD
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
    "def dollars_normalization(email : str)->str:\n",
    "    email_contents = re.sub('[$]+', 'dollar', email)\n",
    "    return email_contents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Radicalisation Des Mots</h2>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": null,
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
   "execution_count": null,
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stemming(email : str)->str:\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "\n",
    "    ps = PorterStemmer()\n",
    "    words = word_tokenize(email)\n",
    "    t_email=\"\"\n",
    "    for w in words:\n",
    "        t_email+=ps.stem(w) + \" \"\n",
    "    return t_email.strip()\n",
    "    "
=======
    "    #insert code"
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
    "    #insert code"
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Suppression Des Non-mots Et Ponctuation</h2>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_word_cleaning(email : str)->str:\n",
    "    # Supprimer la ponctuation\n",
    "    email = email.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Supprimer les mots vides (stop words)\n",
=======
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk  #contient une liste prédéfinie de mots vides \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string #contient une chaîne de caractères prédéfinie qui contient tous les caractères de ponctuation.\n",
    "\n",
    "\n",
    "def non_word_cleaning(email : str)->str:\n",
    "    # Supprimer la ponctuation\n",
    "    email = email.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Convert text to lowercase\n",
    "    email = email.lower()\n",
    "    # Supprimer les mots vides\n",
<<<<<<< HEAD
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = email.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    email = ' '.join(words)\n",
    "    \n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    return email"
=======
    "    return email\n"
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
    "    return email\n"
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 19,
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
   "execution_count": 19,
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_cleaning(email : str)->str:\n",
    "    lines=email.split(\"\\n\")\n",
    "    newlines=[' '.join(line.split()) for line in lines]\n",
    "    while '' in newlines:\n",
    "        newlines.remove('')\n",
    "    content=\"\"\n",
    "    for l in newlines:\n",
    "        content+=l.strip() + \" \"\n",
    "    \n",
    "    return content.strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Netoyage D'emails<h2>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\HP.LAPTOP-ESRMF9MQ/nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\HP.LAPTOP-ESRMF9MQ\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\HP.LAPTOP-ESRMF9MQ/nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\HP.LAPTOP-ESRMF9MQ\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HP01A9~1.LAP\\AppData\\Local\\Temp/ipykernel_12864/1680841782.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mTo\u001b[0m \u001b[0munsubscribe\u001b[0m \u001b[0myourself\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmailing\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msend\u001b[0m \u001b[0man\u001b[0m \u001b[0memail\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgroupname\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0munsubscribe\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0megroups\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \"\"\"\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mclean_email\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_email\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\HP01A9~1.LAP\\AppData\\Local\\Temp/ipykernel_12864/1680841782.py\u001b[0m in \u001b[0;36mclean_email\u001b[1;34m(email)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcleaned_email\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumber_normalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_email\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcleaned_email\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdollars_normalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_email\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcleaned_email\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnon_word_cleaning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_email\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mcleaned_email\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_stemming\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_email\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcleaned_email\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\HP01A9~1.LAP\\AppData\\Local\\Temp/ipykernel_12864/3200200636.py\u001b[0m in \u001b[0;36mnon_word_cleaning\u001b[1;34m(email)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0memail\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Supprimer les mots vides (stop words)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\HP.LAPTOP-ESRMF9MQ/nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\HP.LAPTOP-ESRMF9MQ\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "def clean_email(email):\n",
    "    cleaned_email=email.lower()\n",
    "    cleaned_email=space_cleaning(cleaned_email)\n",
    "    cleaned_email=remove_html(cleaned_email)\n",
    "    cleaned_email=url_normalization(cleaned_email)\n",
    "    cleaned_email=address_normalization(cleaned_email)\n",
    "    cleaned_email=number_normalization(cleaned_email)\n",
    "    cleaned_email=dollars_normalization(cleaned_email)\n",
    "    cleaned_email=non_word_cleaning(cleaned_email)\n",
    "    cleaned_email=word_stemming(cleaned_email)\n",
    "    return cleaned_email\n",
    "\n",
    "#test\n",
    "\n",
    "test_email=\"\"\"\n",
    ">Anyone knows how much it costs to host a web portal ?\n",
    ">\n",
    "Well, it depends on how many visitors youre expecting. This can be anywhere from less than 10 bucks a month to a couple of $100. You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 if youre running something big..\n",
    "\n",
    "\n",
    "To unsubscribe yourself from this mailing list, send an email to: groupname-unsubscribe@egroups.com\n",
    "\"\"\"\n",
    "clean_email(test_email)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
=======
   "execution_count": null,
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
   "execution_count": null,
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T18:30:22.168513Z",
     "start_time": "2023-04-07T18:30:18.030176Z"
    },
    "collapsed": false
   },
<<<<<<< HEAD
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6451 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\HP.LAPTOP-ESRMF9MQ/nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\HP.LAPTOP-ESRMF9MQ\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\HP.LAPTOP-ESRMF9MQ/nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\HP.LAPTOP-ESRMF9MQ\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HP01A9~1.LAP\\AppData\\Local\\Temp/ipykernel_12864/1463962118.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{path}/{k}/{v[i]}\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0memail\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mcleaned_email\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclean_email\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcleaned_email\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\HP01A9~1.LAP\\AppData\\Local\\Temp/ipykernel_12864/1680841782.py\u001b[0m in \u001b[0;36mclean_email\u001b[1;34m(email)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcleaned_email\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumber_normalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_email\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcleaned_email\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdollars_normalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_email\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcleaned_email\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnon_word_cleaning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_email\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mcleaned_email\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_stemming\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_email\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcleaned_email\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\HP01A9~1.LAP\\AppData\\Local\\Temp/ipykernel_12864/3200200636.py\u001b[0m in \u001b[0;36mnon_word_cleaning\u001b[1;34m(email)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0memail\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Supprimer les mots vides (stop words)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\HP.LAPTOP-ESRMF9MQ/nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\HP.LAPTOP-ESRMF9MQ\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "files={d:os.listdir(f\"{path}/{d}\") for d in directories}\n",
    "for k,v in files.items():\n",
    "    for i in tqdm.tqdm(range(len(v))):\n",
    "        with open(f\"{path}/{k}/{v[i]}\",'r',errors=\"ignore\") as f:\n",
    "            email=f.read()\n",
    "        cleaned_email=clean_email(email)\n",
    "        v[i]=cleaned_email"
=======
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "outputs": [],
   "source": [
    "files={d:os.listdir(f\"{path}/{d}\") for d in directories}\n",
    "for k,v in files.items():\n",
    "    for i in range(len(v)):\n",
    "        with open(f\"{path}/{k}/{v[i]}\",'r',errors=\"ignore\") as f:\n",
    "            content=f.read().lower()\n",
    "        \n",
    "        email = space_cleaning(content)\n",
    "        email=remove_html(email)\n",
    "        email=url_normalization(email)\n",
    "        email=address_normalization(email)\n",
    "        email=number_normalization(email)\n",
    "        email=dollars_normalization(email)\n",
    "        email=non_word_cleaning(email)\n",
    "        email=word_stemming(email)\n",
    "        v[i]=email\n",
    "\n",
    "files\n",
    "\n"
<<<<<<< HEAD
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h2>Exportation des emails en fichier CSV</h2>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": null,
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
   "execution_count": null,
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T18:44:30.190844Z",
     "start_time": "2023-04-07T18:44:30.175201Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
    "dataframes={\"easy_ham\":None,\"hard_ham\":None,'spam':None}\n",
    "for k in files:\n",
    "    dataframes[k]=pd.DataFrame(files[k],columns=['text'])\n",
    "    if k=='spam':\n",
    "        dataframes[k][1]=[1]*dataframes[k].shape[0]\n",
    "    else:\n",
    "        dataframes[k][1]=[0]*dataframes[k].shape[0]\n",
    "\n",
    "    dataframes[k][2]=[k]*dataframes[k].shape[0]"
=======
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
    "easy_ham=pd.DataFrame(files['easy_ham'])\n",
    "easy_ham[1]=[0]*easy_ham.shape[0]\n",
    "easy_ham[2]=[\"easy_ham\"]*easy_ham.shape[0]\n",
    "hard_ham=pd.DataFrame(files['hard_ham'])\n",
    "hard_ham[1]=[0]*hard_ham.shape[0]\n",
    "hard_ham[2]=[\"hard_ham\"]*hard_ham.shape[0]\n",
    "spam=pd.DataFrame(files['spam'])\n",
    "spam[1]=[0]*spam.shape[0]\n",
    "spam[2]=[\"spam\"]*spam.shape[0]\n",
    "\n",
    "df=pd.concat([easy_ham,hard_ham,spam],axis=0)\n",
    "df.shape"
<<<<<<< HEAD
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label_num</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01811.e6ab34fdde98dbbb9beabd7cd99028d7</td>\n      <td>0</td>\n      <td>easy_ham</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00144.a439c28b51d6b53f4fbf3bf427b55ed2</td>\n      <td>1</td>\n      <td>spam</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0152.11f72139fb68f9d4fdc1d72d6803437c</td>\n      <td>0</td>\n      <td>hard_ham</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01479.c8a6082ee6a9e21154786f69c71b95bd</td>\n      <td>0</td>\n      <td>easy_ham</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00595.7182665eb052808e2061bacbc75ed5ee</td>\n      <td>0</td>\n      <td>easy_ham</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                     text  label_num     label\n0  01811.e6ab34fdde98dbbb9beabd7cd99028d7          0  easy_ham\n1  00144.a439c28b51d6b53f4fbf3bf427b55ed2          1      spam\n2   0152.11f72139fb68f9d4fdc1d72d6803437c          0  hard_ham\n3  01479.c8a6082ee6a9e21154786f69c71b95bd          0  easy_ham\n4  00595.7182665eb052808e2061bacbc75ed5ee          0  easy_ham"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([v for k,v in dataframes.items()],axis=0)\n",
    "df.columns=['text','label_num','label']\n",
    "df=shuffle(df).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
=======
   "execution_count": null,
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
   "execution_count": null,
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T18:45:14.246248Z",
     "start_time": "2023-04-07T18:45:13.262137Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"./data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
<<<<<<< HEAD
   "version": "3.9.12"
=======
   "version": "3.9.7"
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
   "version": "3.9.7"
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
<<<<<<< HEAD
<<<<<<< HEAD
}
=======
}
>>>>>>> 9633bed82ec4699343020cf3d06240494938d02f
=======
}
>>>>>>> ed4a4d91e3201448bcefab2328566b46eb231aa2
